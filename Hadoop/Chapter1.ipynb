{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hadoop Distributed File System (HDFS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Hadoop Distributed File System (HDFS) is a Java-based dis‐\n",
    "tributed, scalable, and portable filesystem designed to span large\n",
    "clusters of commodity servers. The design of HDFS is based on GFS,\n",
    "the Google File System\n",
    "- HDFS is designed to store a lot of information, typically petabytes\n",
    "(for very large files), gigabytes, and terabytes. This is accomplished\n",
    "by using a block-structured filesystem. Individual files are split into\n",
    "fixed-size blocks that are stored on machines across the cluster. Files\n",
    "made of several blocks generally do not have all of their blocks\n",
    "stored on a single machine.\n",
    "- a Python client library is intro‐\n",
    "duced that enables HDFS to be accessed programmatically from\n",
    "within Python applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of HDFS\n",
    "-  __ NameNode__ e holds the metadata for the filesystem\n",
    "  -  the most important machine in HDFS. It stores\n",
    "metadata for the entire filesystem: filenames, file permissions, and\n",
    "the location of each block of each file\n",
    "-  __DataNode__ processes store the blocks that make up the files. \n",
    "- The NameNode and DataNode processes can run\n",
    "on a single machine\n",
    "- HDFS clusters commonly consist of a dedi‐\n",
    "cated server running the NameNode process and possibly thousands\n",
    "of machines running the DataNode process\n",
    "- The example in Figure 1-1 illustrates the mapping of files to blocks\n",
    "in the NameNode, and the storage of blocks and their replicas\n",
    "within the DataNodes.\n",
    "<img src='images/f1.1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`$ hdfs COMMAND [-option <arg>]`\n",
    "The COMMAND argument instructs which functionality of HDFS will\n",
    "be used. The -option argument is the name of a specific option for\n",
    "the specified command, and <arg> is one or more arguments that\n",
    "that are specified for this option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common File Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List Directory Contents<br>\n",
    "To list the contents of a directory in HDFS, use the -ls command:<br>\n",
    "```\n",
    "$ hdfs dfs -ls\n",
    "$ ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Providing -ls with the forward slash (/) as an argument displays\n",
    "the contents of the root of HDFS:\n",
    "```$ hdfs dfs -ls /\n",
    "Found 2 items\n",
    "drwxr-xr-x - hadoop supergroup 0 2015-09-20 14:36 /hadoop\n",
    "drwx------ - hadoop supergroup 0 2015-09-20 14:36 /tmp```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Directory\n",
    "`$ hdfs dfs -mkdir /user`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a home directory for the current user, hduser, use the\n",
    "-mkdir command again:<br>\n",
    "`$ hdfs dfs -mkdir /user/hduser`<br>\n",
    "Use the -ls command to verify that the previous directories were\n",
    "created<br>\n",
    "```$ hdfs dfs -ls -R /user\n",
    "drwxr-xr-x - hduser supergroup 0 2015-09-22 18:01 /user/\n",
    "hduser```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy Data onto HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " data can be\n",
    "uploaded to the user’s HDFS home directory with the -put com‐\n",
    "mand:<br>\n",
    "```\n",
    "$ hdfs dfs -put /home/hduser/input.txt /user/hduser\n",
    "```\n",
    "\n",
    "Use the -ls command to verify that input.txt was moved to HDFS:\n",
    "```$ hdfs dfs -ls\n",
    "Found 1 items\n",
    "-rw-r--r-- 1 hduser supergroup 52 2015-09-20 13:20\n",
    "input.txt```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Data from HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The following com‐\n",
    "mand uses -cat to display the contents of /user/hduser/input.txt:\n",
    "```\n",
    "$ hdfs dfs -cat input.txt\n",
    "jack be nimble\n",
    "jack be quick\n",
    "jack jumped over the candlestick```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can also be copied from HDFS to the local filesystem using the\n",
    "-get command. The -get command is the opposite of the -put\n",
    "command:\n",
    "```$ hdfs dfs -get input.txt /home/hduser```\n",
    "This command copies input.txt from /user/hduser on HDFS\n",
    "to /home/hduser on the local filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
